#####################################################################
# NOTES
#
# cannot use '%' in config file entries (watch your URLs!)
#
# This file may be overwritten by git pulls. To create a custom config
# create a copy and specify to use the custom config using the -c flag
# at program startup
#
#
#####################################################################

[main_config]

# Default output directory is a subdir of the application working dir
# don't try to use "~" in path to specify user home directory!
output_dir = output/

# Suppress tool output to terminal
suppress_out = false

# Prompt for re-run of tools on targets if detected they have already been run
# Set to false (default) to just skip duplicate tool runs
prompt_tool_reruns = false

# Output format for cutycapt to output webpages
# svg,ps,pdf,itext,html,rtree,png,jpeg,mng,tiff,gif,bmp,ppm,xbm,xpm
website_output_format = pdf

# Limit harvested emails to those matching specified domains
# Setting to true (default) will only report email addresses which correspond
# with specified TLD
limit_email_domains = true

#####################################################################
# Tool config section
#
# Placeholders will be replaced as follows during script execution:
#   [PROJECT] - will be replaced with project name
#   [TARGET] - domain specified in command line or target IP addresses discovered
#   [OUTPUT] - will be replaced with output file name for tools that output to
#               file instead of screen
#
# Parameters for tool entries (a tool should either be a URL or command):
#   command = command line to be executed
#       email_regex = regex to be applied to output to extract email addresses
#       ip_regex = regex to be applied to output to extract IP addresses
#       dns_regex = regex to be applied to output to extract
#       cleanup_regex = regex to clean up tool output to make more readable
#
#   url = OSINT site url to be captured
#   delay = delay after successful load before screenshot (default to 1000 ms)
#
#   run_domain = true - command / site will be run on TLD supplied
#   run_ip = true - command / site will be run on discovered hosts by ip address
#   run_dns = true - command / site will be run on discovered hosts by dns name
#   output_subdir - subdirectory of main output directory for tool output
#   ouput_format - file extension of output file for tools that output to file
#                   as opposed to screen
#   aggressive = true - command is aggressive (not passive) and will directly
#                   communicate with target. Aggressive tools only executed in
#                   aggressive mode.
#
#   Note - DNS/IP resolution is performed so these lists will have duplicate hosts
#   in them - it is generally better to run a tool/site against an IP address
#   using the run_ip option rather than a dns name if possible since this is likely
#   a more complete list of targets. 
#   Use the run_dns option for tools / sites that require a dns name
#
#####################################################################


#####################################################################
# Domains
#
# Runs against a TLD (e.g google.com)
# "[TARGET]" parameter is replaced with the specified domain name
#
#####################################################################

[nslookup]
command = nslookup -type=any [TARGET] 8.8.8.8
run_domain = true
ip_regex = Address: (\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b)
output_subdir = domain

[whois]
command = whois [TARGET]
run_domain = true
email_regex = (\b[\w._-]+@[\w._-]+\.[\w]{2,4}\b)
output_subdir = domain

[theharvester]
command = theharvester -d [TARGET] -b all
run_domain = true
email_regex = (\b[\w._-]+@[\w._-]+\.[\w]{2,4}\b)
ip_regex = (\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b)
dns_regex = (?:\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b):(.*)
output_subdir = domain

[msf_email]
command = msfconsole -n -q -x "use gather/search_email_collector;set domain [TARGET];run;exit"
run_domain = true
cleanup_regex = .*0m(.*)
email_regex = (\b[\w._-]+@[\w._-]+\.[\w]{2,4}\b)
output_subdir = domain

## Note - fierce will sometimes stumble on wildcard domains and generate massive amounts of junk
## Comment out if this happens!
[fierce]
command = fierce -dns [TARGET] -dnsserver 8.8.8.8
run_domain = true
ip_regex = (\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b)(?!-)
dns_regex = (?:\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b)\s(.*)
output_subdir = domain

[dnsrecon]
#TODO - need to add SPF and possibly selected MX record checks to ip/dns regex
command = dnsrecon -d [TARGET] -a -s -g -z
#command =  dnsrecon -d [TARGET] -t std,brt,srv,axfr,goo -D /usr/share/dnsrecon/namelist.txt -f
run_domain = true
ip_regex = \sA\s.*\s(\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b)
dns_regex = \sA\s(\S*)\s
output_subdir = domain

[scrape_email-format.com]
command = curl http://www.email-format.com/d/[TARGET]/ | grep -o [A-Za-z0-9_.]*@[A-Za-z0-9_.]*[.][A-Za-z]*
run_domain = true
output_subdir = domain
email_regex = (\b[\w._-]+@[\w._-]+\.[\w]{2,4}\b)

[intodns]
url = "http://www.intodns.com/[TARGET]"
run_domain = true
output_subdir = domain

[myipneighbors]
url = "http://www.myipneighbors.net/?s=[TARGET]"
run_domain = true
output_subdir = domain

[urlvoid_domain]
url = "http://www.urlvoid.com/scan/[TARGET]"
run_domain = true
output_subdir = domain

[centralops_domain]
url = "http://centralops.net/co/DomainDossier.aspx?addr=[TARGET]&dom_whois=true&dom_dns=true&net_whois=true"
run_domain = true
output_subdir = domain

[mxtoolbox_domain]
url = "http://mxtoolbox.com/domain/[TARGET]/"
delay=3000
run_domain = true
output_subdir = domain

[mxtoolbox_dns]
url = "http://mxtoolbox.com/SuperTool.aspx?action=dns:[TARGET]&run=toolpage"
delay=3000
run_domain = true
output_subdir = domain

[shodan_domain]
url = "https://www.shodan.io/search?query=[TARGET]"
run_domain = true
output_subdir = domain

#####################################################################
# Discovered hosts (IP addresses)
#
# Runs against IP addresses discovered in initial enumerations
# "[TARGET]" is replaced with discovered target addresses
#
# Note - don't have to run nslookup on hosts - this is hardcoded into
# script for host-ip resolution and association
#
#####################################################################

[nmap-scripts]
command = nmap -sn --script external [TARGET]
run_ip = true
output_subdir = hosts

[myipneighbors]
url = "http://www.myipneighbors.net/?s=[TARGET]"
run_ip = true
output_subdir = hosts

[centralops]
url = "http://centralops.net/co/DomainDossier.aspx?addr=[TARGET]&dom_whois=true&dom_dns=true&traceroute=true&net_whois=true&svc_scan=true"
run_ip = true
output_subdir = hosts

[mxtoolbox_blacklist]
url = "http://mxtoolbox.com/SuperTool.aspx?action=blacklist:[TARGET]&run=toolpage"
delay=3000
run_ip = true
output_subdir = hosts

[shodan]
url = "https://www.shodan.io/search?query=[TARGET]"
run_ip = true
output_subdir = hosts

#####################################################################
# Discovered hosts (DNS names)
#
# Runs against dns names discovered in initial enumerations
# "[TARGET]" is replaced with discovered target addresses
#
#####################################################################

[urlvoid]
url = "http://www.urlvoid.com/scan/[TARGET]"
run_dns = true
output_subdir = hosts

[netcraft]
url = "http://toolbar.netcraft.com/site_report?url=[TARGET]"
run_dns = true
output_subdir = hosts


#####################################################################
# Recon-ng
#####################################################################
[recon-ng-add-domain]
command = recon-cli -w [PROJECT] -C "add domains [TARGET]"
run_domain = true
output_format=none

#[recon-ng-metacrawler]
#command = recon-cli -x -w [PROJECT] -m recon/domains-contacts/metacrawler
#run_once = true
#output_format=none

[recon-ng-pgp_search]
command = recon-cli -x -w [PROJECT] -m recon/domains-contacts/pgp_search
run_once = true
output_format=none

[recon-ng-salesmaple]
command = recon-cli -x -w [PROJECT] -m recon/domains-contacts/salesmaple
run_once = true
output_format=none

[recon-ng-whois]
command = recon-cli -x -w [PROJECT] -m recon/domains-contacts/whois_pocs
run_once=true
output_format=none

[recon-ng-baidu_site]
command = recon-cli -x -w [PROJECT] -m recon/domains-hosts/baidu_site
run_once = true
output_format=none

[recon-ng-bing_domain_api]
command = recon-cli -x -w [PROJECT] -m recon/domains-hosts/bing_domain_api
run_once = true
output_format=none

[recon-ng-bing_domain_web]
command = recon-cli -x -w [PROJECT] -m recon/domains-hosts/bing_domain_web
run_once = true
output_format=none

[recon-ng-brute_hosts]
command = recon-cli -x -w [PROJECT] -m recon/domains-hosts/brute_hosts
run_once = true
output_format=none

[recon-ng-google_site_api]
command = recon-cli -x -w [PROJECT] -m recon/domains-hosts/google_site_api
run_once = true

#[recon-ng-google_site_web]
#command = recon-cli -x -w [PROJECT] -m recon/domains-hosts/google_site_web
#run_once = true
#output_format=none

[recon-ng-netcraft]
command = recon-cli -x -w [PROJECT] -m recon/domains-hosts/netcraft
run_once = true

[recon-ng-shodan_hostname]
command = recon-cli -x -w [PROJECT] -m recon/domains-hosts/shodan_hostname
run_once = true
output_format=none

[recon-ng-ssl_san]
command = recon-cli -x -w [PROJECT] -m recon/domains-hosts/ssl_san
run_once = true

[recon-ng-vpnhunter]
command = recon-cli -x -w [PROJECT] -m recon/domains-hosts/vpnhunter
run_once = true

[recon-ng-yahoo_domain]
command = recon-cli -x -w [PROJECT] -m recon/domains-hosts/yahoo_domain
run_once = true
output_format=none

[recon-ng-ghdb]
command = recon-cli -x -w [PROJECT] -m recon/domains-vulnerabilities/ghdb
run_once = true
output_format=none

[recon-ng-punkspider]
command = recon-cli -x -w [PROJECT] -m recon/domains-vulnerabilities/punkspider
run_once = true
output_format=none

[recon-ng-xssed]
command = recon-cli -x -w [PROJECT] -m recon/domains-vulnerabilities/xssed
run_once = true
output_format=none

[recon-ng-xssposed]
command = recon-cli -x -w [PROJECT] -m recon/domains-vulnerabilities/xssposed
run_once = true

[recon-ng-bing_ip]
command = recon-cli -x -w [PROJECT] -m recon/hosts-hosts/bing_ip
run_once = true
output_format=none

[recon-ng-ip_neighbor]
command = recon-cli -x -w [PROJECT] -m recon/hosts-hosts/ip_neighbor
run_once = true

[recon-ng-ipinfodb]
command = recon-cli -x -w [PROJECT] -m recon/hosts-hosts/ipinfodb
run_once = true
output_format=none

[recon-ng-resolve]
command = recon-cli -x -w [PROJECT] -m recon/hosts-hosts/resolve
run_once = true

[recon-ng-reverse_resolve]
command = recon-cli -x -w [PROJECT] -m recon/hosts-hosts/reverse_resolve
run_once = true
output_format=none

[recon-ng-ssltools]
command = recon-cli -x -w [PROJECT] -m recon/hosts-hosts/ssltools
run_once = true

[recon-ng-shodan_ip]
command = recon-cli -x -w [PROJECT] -m recon/hosts-ports/shodan_ip
run_once = true
output_format=none

[recon-ng-freegeoip]
command = recon-cli -x -w [PROJECT] -m recon/hosts-hosts/freegeoip
run_once = true
output_format=none

[recon-ng-report]
command = recon-cli -x -w [PROJECT] -m reporting/html -o Filename=$PWD/[OUTPUT] -o CREATOR="pasv-agrsv by IS Audits & Consulting" -o Customer="[PROJECT]"
output_format = html
run_once = true
output_subdir = domain  

#####################################################################
# Aggressive tests  
#####################################################################

[website-screenshot]
command = cutycapt \-\-url=[TARGET] \-\-delay=1000 \-\-out=[OUTPUT]
output_format = pdf
run_ip = true
run_dns = true
output_subdir = hosts
aggressive = true

[webshag-spider]
#NOTE - webshag does not like IP addresses specified in output file name
#since we use those for naming the run output, only run on dns
command = webshag-cli -m spider -x -f [OUTPUT] [TARGET]
output_format = html
run_dns = true
output_subdir = hosts
aggressive = true
email_regex = (\b[\w._-]+@[\w._-]+\.[\w]{2,4}\b)

[nmap-email-harvester]
command = nmap -p80,443 --script=http-email-harvest [TARGET]
run_dns = true
output_subdir = hosts
aggressive = true
email_regex = (\b[\w._-]+@[\w._-]+\.[\w]{2,4}\b)