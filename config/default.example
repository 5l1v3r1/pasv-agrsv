#####################################################################
# NOTES
#
# cannot use '%' in config file entries (watch your URLs!)
#
# This file may be overwritten by git pulls. To create a custom config
# create a copy and specify to use the custom config using the -c flag
# at program startup
#
#
#####################################################################

[main_config]
# Default output directory is a subdir of the application working dir
# don't try to use "~" in path to specify user home directory!
output_dir = output/

# Suppress tool output to terminal
suppress_out = false

# Output format for cutycapt to output webpages
# svg,ps,pdf,itext,html,rtree,png,jpeg,mng,tiff,gif,bmp,ppm,xbm,xpm
website_output_format = pdf

#####################################################################
# Tool config section
#
# Placeholders will be replaced as follows during script execution:
#   [TARGET] - domain specified in command line or target IP addresses discovered
#
# Parameters for tool entries (a tool should either be a URL or command):
#   command = command line to be executed
#       email_regex = regex to be applied to output to extract email addresses
#       ip_regex = regex to be applied to output to extract IP addresses
#       dns_regex = regex to be applied to output to extract
#       cleanup_regex = regex to clean up tool output to make more readable
#
#   url = OSINT site url to be captured
#
#   run_domain = true - command / site will be run on TLD supplied
#   run_ip = true - command / site will be run on discovered hosts by ip address
#   run_dns = true - command / site will be run on discovered hosts by dns name
#   output_subdir = subdirectory of main output directory for tool output
#
#   Note - DNS/IP resolution is performed so these lists will have duplicate hosts
#   in them - it is generally better to run a tool/site against an IP address
#   using the run_ip option rather than a dns name if possible since this is likely
#   a more complete list of targets. 
#   Use the run_dns option for tools / sites that require a dns name
#
#####################################################################


#####################################################################
# Domains
#
# Runs against a TLD (e.g google.com)
# "[TARGET]" parameter is replaced with the specified domain name
#
#####################################################################

[nslookup]
command = nslookup [TARGET]
run_domain = true
ip_regex = Address:\s(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})
output_subdir = domain

[whois]
command = whois [TARGET]
run_domain = true
email_regex = (\b[\w._-]+@[\w._-]+\.[\w]{2,4}\b)
output_subdir = domain

[theharvester]
command = theharvester -d [TARGET] -b all
run_domain = true
email_regex = (\b[\w._-]+@[\w._-]+\.[\w]{2,4}\b)
ip_regex = (\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b)
dns_regex = (?:\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b):(.*)
output_subdir = domain

[msf_email]
command = msfconsole -n -q -x "use gather/search_email_collector;set domain [TARGET];run;exit"
run_domain = true
cleanup_regex = .*0m(.*)
email_regex = (\b[\w._-]+@[\w._-]+\.[\w]{2,4}\b)
output_subdir = domain

[fierce]
command = fierce -dns [TARGET]
run_domain = true
ip_regex = (\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b)(?!-)
dns_regex = (?:\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b)\s(.*)
output_subdir = domain

[dnsrecon]
#TODO - need to add SPF and possibly selected MX record checks to ip/dns regex
command = dnsrecon -d [TARGET] -a -s -g -z
run_domain = true
ip_regex = \sA\s.*\s(\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b)
dns_regex = \sA\s(\S*)\s
output_subdir = domain

[intodns]
url = "http://www.intodns.com/[TARGET]"
run_domain = true
output_subdir = domain

[myipneighbors]
url = "http://www.myipneighbors.net/?s=[TARGET]"
run_domain = true
output_subdir = domain

[urlvoid_domain]
url = "http://www.urlvoid.com/scan/[TARGET]"
run_domain = true
output_subdir = domain

[centralops_domain]
url = "http://centralops.net/co/DomainDossier.aspx?addr=[TARGET]&dom_whois=true&dom_dns=true&net_whois=true"
run_domain = true
output_subdir = domain

[mxtoolbox_domain]
url = "http://mxtoolbox.com/domain/[TARGET]/"
run_domain = true
output_subdir = domain

[mxtoolbox_dns]
url = "http://mxtoolbox.com/SuperTool.aspx?action=dns:[TARGET]&run=toolpage"
run_domain = true
output_subdir = domain

[shodan_domain]
url = "http://www.shodanhq.com/search?q=[TARGET]"
run_domain = true
output_subdir = domain

[email_format]
url = "http://www.email-format.com/d/[TARGET]/"
run_domain = true
output_subdir = domain


#####################################################################
# Discovered hosts (IP addresses)
#
# Runs against IP addresses discovered in initial enumerations
# "[TARGET]" is replaced with discovered target addresses
#
# Note - don't have to run nslookup on hosts - this is hardcoded into
# script for host-ip resolution and association
#
#####################################################################

[nmap-scripts]
command = nmap -sn --script external [TARGET]
run_ip = true
output_subdir = hosts

[myipneighbors]
url = "http://www.myipneighbors.net/?s=[TARGET]"
run_ip = true
output_subdir = hosts

[centralops]
url = "http://centralops.net/co/DomainDossier.aspx?addr=[TARGET]&dom_whois=true&dom_dns=true&traceroute=true&net_whois=true&svc_scan=true"
run_ip = true
output_subdir = hosts

[mxtoolbox_blacklist]
url = "http://mxtoolbox.com/SuperTool.aspx?action=blacklist:[TARGET]&run=toolpage"
run_ip = true
output_subdir = hosts

[shodan]
url = "http://www.shodanhq.com/search?q=[TARGET]"
run_ip = true
output_subdir = hosts

#####################################################################
# Discovered hosts (DNS names)
#
# Runs against dns names discovered in initial enumerations
# "[TARGET]" is replaced with discovered target addresses
#
#####################################################################

[urlvoid]
url = "http://www.urlvoid.com/scan/[TARGET]"
run_dns = true
output_subdir = hosts

[netcraft]
url = "http://toolbar.netcraft.com/site_report?url=[TARGET]"
run_dns = true
output_subdir = hosts